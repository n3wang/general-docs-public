
Easy
7.1. Robinhood: Say you are building a binary classifier for an unbalanced dataset (where one class is much rarer than the other, say $1 \%$ and $99 \%$, respectively). How do you handle this situation?


7.2. Square: What are some differences you would expect in a model that minimizes squared error versus a model that minimizes absolute error? In which cases would each error metric be appropriate?
7.3. Facebook: When performing $K$-means clustering, how do you choose $k$ ?
7.4. Salesforce: How can you make your models more robust to outliers?
7.5. AQR : Say that you are running a multiple linear regression and that you have reason to believe that several of the predictors are correlated. How will the results of the regression be affected if several are indeed correlated? How would you deal with this problem?
7.6. Point72: Describe the motivation behind random forests. What are two ways in which they improve upon individual decision trees?
7.7. PayPal: Given a large dataset of payment transactions, say we want to predict the likelihood of a given transaction being fraudulent. However, there are many rows with missing values for various columns. How would you deal with this?

7.8. Airbnb: Say you are running a simple logistic regression to solve a problem but find the results to be unsatisfactory. What are some ways you might improve your model, or what other models might you look into using instead?
7.9. Two Sigma: Say you were running a linear regression for a dataset but you accidentally duplicated every data point. What happens to your beta coefficient?
7.10. PWC: Compare and contrast gradient boosting and random forests.
7.11. DoorDash: Say that DoorDash is launching in Singapore. For this new market, you want to predict the estimated time of arrival (ETA) for a delivery to reach a customer after an order has been placed on the app. From an earlier beta test in Singapore, there were 10,000 deliveries made. Do you have enough training data to create an accurate ETA model?